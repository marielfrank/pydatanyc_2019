{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for noise removal\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk for some preprocessing wonders\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mariel/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/mariel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/mariel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download nltk corpora\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passage from Through the Looking Glass\n",
    "text = \"The shop seemed to be full of all manner of curious things â€” but the oddest part of it all was, that whenever she looked hard at any shelf, to make out exactly what it had on it, that particular shelf was always quite empty: though the others round it were crowded as full as they could hold.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shop seemed to be full of all manner of curious things but the oddest part of it all was that whenever she looked hard at any shelf to make out exactly what it had on it that particular shelf was always quite empty though the others round it were crowded as full as they could hold \n"
     ]
    }
   ],
   "source": [
    "# noise removal using regex\n",
    "cleaned = re.sub('\\W+', ' ', text)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'shop', 'seemed', 'to', 'be', 'full', 'of', 'all', 'manner', 'of', 'curious', 'things', 'but', 'the', 'oddest', 'part', 'of', 'it', 'all', 'was', 'that', 'whenever', 'she', 'looked', 'hard', 'at', 'any', 'shelf', 'to', 'make', 'out', 'exactly', 'what', 'it', 'had', 'on', 'it', 'that', 'particular', 'shelf', 'was', 'always', 'quite', 'empty', 'though', 'the', 'others', 'round', 'it', 'were', 'crowded', 'as', 'full', 'as', 'they', 'could', 'hold']\n"
     ]
    }
   ],
   "source": [
    "# tokenization using word_tokenize() from nltk\n",
    "tokenized = word_tokenize(cleaned)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed text:\n",
      " ['the', 'shop', 'seem', 'to', 'be', 'full', 'of', 'all', 'manner', 'of', 'curiou', 'thing', 'but', 'the', 'oddest', 'part', 'of', 'it', 'all', 'wa', 'that', 'whenev', 'she', 'look', 'hard', 'at', 'ani', 'shelf', 'to', 'make', 'out', 'exactli', 'what', 'it', 'had', 'on', 'it', 'that', 'particular', 'shelf', 'wa', 'alway', 'quit', 'empti', 'though', 'the', 'other', 'round', 'it', 'were', 'crowd', 'as', 'full', 'as', 'they', 'could', 'hold']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokenized]\n",
    "print(\"Stemmed text:\\n\", stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized text:\n",
      " ['The', 'shop', 'seemed', 'to', 'be', 'full', 'of', 'all', 'manner', 'of', 'curious', 'thing', 'but', 'the', 'oddest', 'part', 'of', 'it', 'all', 'wa', 'that', 'whenever', 'she', 'looked', 'hard', 'at', 'any', 'shelf', 'to', 'make', 'out', 'exactly', 'what', 'it', 'had', 'on', 'it', 'that', 'particular', 'shelf', 'wa', 'always', 'quite', 'empty', 'though', 'the', 'others', 'round', 'it', 'were', 'crowded', 'a', 'full', 'a', 'they', 'could', 'hold']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(token) for token in tokenized]\n",
    "print(\"Lemmatized text:\\n\", lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
